{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79f741f1-f846-4eb2-9b64-87eb67f23e99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T21:21:36.132660Z",
     "iopub.status.busy": "2024-10-06T21:21:36.132188Z",
     "iopub.status.idle": "2024-10-06T21:21:36.138103Z",
     "shell.execute_reply": "2024-10-06T21:21:36.137201Z",
     "shell.execute_reply.started": "2024-10-06T21:21:36.132619Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import to_timestamp,current_timestamp\n",
    "from pyspark.sql.types import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "379aaa78-69b7-4cce-80f8-a8aa30f0c02b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T03:03:46.377769Z",
     "iopub.status.busy": "2024-10-06T03:03:46.377257Z",
     "iopub.status.idle": "2024-10-06T03:03:46.413457Z",
     "shell.execute_reply": "2024-10-06T03:03:46.412236Z",
     "shell.execute_reply.started": "2024-10-06T03:03:46.377723Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "emptyRdd= spark.sparkContext.emptyRDD() #empty rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05ac2648-84df-4375-98bc-4640a4285594",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T05:57:11.962896Z",
     "iopub.status.busy": "2024-10-05T05:57:11.962428Z",
     "iopub.status.idle": "2024-10-05T05:57:11.968231Z",
     "shell.execute_reply": "2024-10-05T05:57:11.967254Z",
     "shell.execute_reply.started": "2024-10-05T05:57:11.962853Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.RDD'>\n"
     ]
    }
   ],
   "source": [
    "print(type(emptyRdd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a16024d-7d59-4a1c-aa5d-ff8c568f57a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T03:03:49.214707Z",
     "iopub.status.busy": "2024-10-06T03:03:49.214193Z",
     "iopub.status.idle": "2024-10-06T03:03:49.339714Z",
     "shell.execute_reply": "2024-10-06T03:03:49.338375Z",
     "shell.execute_reply.started": "2024-10-06T03:03:49.214662Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rdd2=spark.sparkContext.parallelize([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14bd490b-8a93-47f8-ae07-e16e64ece8d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T03:03:51.122233Z",
     "iopub.status.busy": "2024-10-06T03:03:51.121738Z",
     "iopub.status.idle": "2024-10-06T03:03:51.127547Z",
     "shell.execute_reply": "2024-10-06T03:03:51.126601Z",
     "shell.execute_reply.started": "2024-10-06T03:03:51.122187Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.RDD'>\n"
     ]
    }
   ],
   "source": [
    "print(type(rdd2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfa376b7-b740-4ef0-a826-4706557a2e13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T05:52:54.789234Z",
     "iopub.status.busy": "2024-10-05T05:52:54.788716Z",
     "iopub.status.idle": "2024-10-05T05:52:55.281242Z",
     "shell.execute_reply": "2024-10-05T05:52:55.279917Z",
     "shell.execute_reply.started": "2024-10-05T05:52:54.789185Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4897ae6f-8295-47df-a2bb-e3db17fbefa3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T03:03:54.583122Z",
     "iopub.status.busy": "2024-10-06T03:03:54.582607Z",
     "iopub.status.idle": "2024-10-06T03:03:54.588826Z",
     "shell.execute_reply": "2024-10-06T03:03:54.587773Z",
     "shell.execute_reply.started": "2024-10-06T03:03:54.583076Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "        StructField('Firstname',StringType(),True),\n",
    "        StructField('middlename',StringType(),True),\n",
    "        StructField('lastname',StringType(),True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "918b0f16-8fea-4956-8d10-3fb646f07009",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T03:03:56.057145Z",
     "iopub.status.busy": "2024-10-06T03:03:56.056649Z",
     "iopub.status.idle": "2024-10-06T03:03:58.865330Z",
     "shell.execute_reply": "2024-10-06T03:03:58.864205Z",
     "shell.execute_reply.started": "2024-10-06T03:03:56.057100Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1= spark.createDataFrame(rdd2,schema)\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "731e10e8-79c6-403d-b113-fc4296ebcf16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-05T06:00:56.532157Z",
     "iopub.status.busy": "2024-10-05T06:00:56.531671Z",
     "iopub.status.idle": "2024-10-05T06:00:56.567849Z",
     "shell.execute_reply": "2024-10-05T06:00:56.566825Z",
     "shell.execute_reply.started": "2024-10-05T06:00:56.532113Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Firstname: string, middlename: string, lastname: string]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=rdd2.toDF(schema)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "896e90ae-45d6-4eab-a979-61fa515f4130",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T03:03:58.867938Z",
     "iopub.status.busy": "2024-10-06T03:03:58.867321Z",
     "iopub.status.idle": "2024-10-06T03:03:58.910651Z",
     "shell.execute_reply": "2024-10-06T03:03:58.909593Z",
     "shell.execute_reply.started": "2024-10-06T03:03:58.867876Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2= spark.createDataFrame([],schema)\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3990577-2e02-470a-a2d0-fe8cbf3fce86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T03:04:01.481984Z",
     "iopub.status.busy": "2024-10-06T03:04:01.481476Z",
     "iopub.status.idle": "2024-10-06T03:04:01.518498Z",
     "shell.execute_reply": "2024-10-06T03:04:01.517463Z",
     "shell.execute_reply.started": "2024-10-06T03:04:01.481938Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2= spark.createDataFrame([],StructType([]))\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d36bcd35-202b-4921-a9f1-8a60d33897c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T03:36:50.086496Z",
     "iopub.status.busy": "2024-10-06T03:36:50.086008Z",
     "iopub.status.idle": "2024-10-06T03:36:50.091682Z",
     "shell.execute_reply": "2024-10-06T03:36:50.090744Z",
     "shell.execute_reply.started": "2024-10-06T03:36:50.086452Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " #1 convert-column-python-list.py\n",
    "data = [(\"James\",\"Smith\",\"USA\",\"CA\"),(\"Michael\",\"Rose\",\"USA\",\"NY\"), \\\n",
    "    (\"Robert\",\"Williams\",\"USA\",\"CA\"),(\"Maria\",\"Jones\",\"USA\",\"FL\") \\\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca2bbb0e-318b-48c6-a412-a126aa4139c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T03:05:51.403626Z",
     "iopub.status.busy": "2024-10-06T03:05:51.399674Z",
     "iopub.status.idle": "2024-10-06T03:05:51.472272Z",
     "shell.execute_reply": "2024-10-06T03:05:51.471129Z",
     "shell.execute_reply.started": "2024-10-06T03:05:51.403551Z"
    }
   },
   "outputs": [],
   "source": [
    "columns=[\"firstname\",\"lastname\",\"country\",\"state\"]\n",
    "df=spark.createDataFrame(data=data,schema=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15d4a603-f93b-4a18-b21c-5a79dccb8b9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T03:06:00.584807Z",
     "iopub.status.busy": "2024-10-06T03:06:00.584075Z",
     "iopub.status.idle": "2024-10-06T03:06:18.277141Z",
     "shell.execute_reply": "2024-10-06T03:06:18.276086Z",
     "shell.execute_reply.started": "2024-10-06T03:06:00.584744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/10/06 03:06:02 INFO src/lib.rs: Boson native library initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+-----+\n",
      "|firstname|lastname|country|state|\n",
      "+---------+--------+-------+-----+\n",
      "|    James|   Smith|    USA|   CA|\n",
      "|  Michael|    Rose|    USA|   NY|\n",
      "|   Robert|Williams|    USA|   CA|\n",
      "|    Maria|   Jones|    USA|   FL|\n",
      "+---------+--------+-------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(firstname='James', lastname='Smith', country='USA', state='CA'), Row(firstname='Michael', lastname='Rose', country='USA', state='NY'), Row(firstname='Robert', lastname='Williams', country='USA', state='CA'), Row(firstname='Maria', lastname='Jones', country='USA', state='FL')]\n"
     ]
    }
   ],
   "source": [
    "df.show()\n",
    "print(df.collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3236add-7787-4779-8a2c-fe83d8f8d9e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T03:11:32.678639Z",
     "iopub.status.busy": "2024-10-06T03:11:32.678156Z",
     "iopub.status.idle": "2024-10-06T03:11:34.821225Z",
     "shell.execute_reply": "2024-10-06T03:11:34.820113Z",
     "shell.execute_reply.started": "2024-10-06T03:11:32.678588Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CA', 'NY', 'CA', 'FL']\n"
     ]
    }
   ],
   "source": [
    "states1=df.rdd.map(lambda x: x[3]).collect()\n",
    "print(states1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68b56441-3e75-4f8e-bc77-7b2e8657032c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T03:13:07.452707Z",
     "iopub.status.busy": "2024-10-06T03:13:07.452226Z",
     "iopub.status.idle": "2024-10-06T03:13:07.457154Z",
     "shell.execute_reply": "2024-10-06T03:13:07.456275Z",
     "shell.execute_reply.started": "2024-10-06T03:13:07.452664Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea1a8677-b278-4a9d-9e17-d248f6d0c70c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T03:15:55.245028Z",
     "iopub.status.busy": "2024-10-06T03:15:55.244569Z",
     "iopub.status.idle": "2024-10-06T03:15:55.249923Z",
     "shell.execute_reply": "2024-10-06T03:15:55.249024Z",
     "shell.execute_reply.started": "2024-10-06T03:15:55.244984Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "res=list(OrderedDict.fromkeys(states1)) # convert-column-python-list.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e682a40d-b0a7-406c-9840-0346916baf5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T03:15:57.605532Z",
     "iopub.status.busy": "2024-10-06T03:15:57.605037Z",
     "iopub.status.idle": "2024-10-06T03:15:57.610803Z",
     "shell.execute_reply": "2024-10-06T03:15:57.609899Z",
     "shell.execute_reply.started": "2024-10-06T03:15:57.605483Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CA', 'NY', 'FL']\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ef250cd-6a93-4e03-af6c-cea02c1e7c80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T03:21:03.632493Z",
     "iopub.status.busy": "2024-10-06T03:21:03.631828Z",
     "iopub.status.idle": "2024-10-06T03:21:05.861810Z",
     "shell.execute_reply": "2024-10-06T03:21:05.860702Z",
     "shell.execute_reply.started": "2024-10-06T03:21:03.632429Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CA', 'NY', 'CA', 'FL']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states4= df.select(\"state\").rdd.map(lambda x : x[0]).collect()\n",
    "states4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f9546239-6102-47bd-a721-f6574bea6cb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T03:21:36.188057Z",
     "iopub.status.busy": "2024-10-06T03:21:36.187571Z",
     "iopub.status.idle": "2024-10-06T03:21:38.459732Z",
     "shell.execute_reply": "2024-10-06T03:21:38.458737Z",
     "shell.execute_reply.started": "2024-10-06T03:21:36.188014Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CA', 'NY', 'CA', 'FL']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states4= df.select(\"state\").rdd.flatMap(lambda x : x).collect()\n",
    "states4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f9a3c10-b972-4d0a-b516-b8523c2faddf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T03:22:39.708155Z",
     "iopub.status.busy": "2024-10-06T03:22:39.707183Z",
     "iopub.status.idle": "2024-10-06T03:22:41.989101Z",
     "shell.execute_reply": "2024-10-06T03:22:41.988068Z",
     "shell.execute_reply.started": "2024-10-06T03:22:39.708110Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Smith', 'Rose', 'Williams', 'Jones']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.map(lambda x: x.lastname).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "35d10f72-6ab7-46ea-94f6-16735e07f35f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T03:34:14.358093Z",
     "iopub.status.busy": "2024-10-06T03:34:14.357088Z",
     "iopub.status.idle": "2024-10-06T03:34:16.631818Z",
     "shell.execute_reply": "2024-10-06T03:34:16.630797Z",
     "shell.execute_reply.started": "2024-10-06T03:34:14.358047Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['James', 'Michael', 'Robert', 'Maria']\n"
     ]
    }
   ],
   "source": [
    "pandasDF= df.select(\"firstname\",\"lastname\").toPandas()\n",
    "print(list(pandasDF[\"firstname\"]))\n",
    "res=list(pandasDF[\"lastname\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e566d7d2-a285-493e-96a8-bdf426a31959",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T03:32:49.895848Z",
     "iopub.status.busy": "2024-10-06T03:32:49.895381Z",
     "iopub.status.idle": "2024-10-06T03:32:49.911253Z",
     "shell.execute_reply": "2024-10-06T03:32:49.910334Z",
     "shell.execute_reply.started": "2024-10-06T03:32:49.895803Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "      <td>m</td>\n",
       "      <td>i</td>\n",
       "      <td>t</td>\n",
       "      <td>h</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>o</td>\n",
       "      <td>s</td>\n",
       "      <td>e</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W</td>\n",
       "      <td>i</td>\n",
       "      <td>l</td>\n",
       "      <td>l</td>\n",
       "      <td>i</td>\n",
       "      <td>a</td>\n",
       "      <td>m</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>J</td>\n",
       "      <td>o</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3     4     5     6     7\n",
       "0  S  m  i  t     h  None  None  None\n",
       "1  R  o  s  e  None  None  None  None\n",
       "2  W  i  l  l     i     a     m     s\n",
       "3  J  o  n  e     s  None  None  None"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df10 = pd.DataFrame.from_records()\n",
    "df10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "07e5a425-2891-4a20-bec7-6d85a8bfa1d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T03:35:33.967028Z",
     "iopub.status.busy": "2024-10-06T03:35:33.966554Z",
     "iopub.status.idle": "2024-10-06T03:35:36.223483Z",
     "shell.execute_reply": "2024-10-06T03:35:36.222333Z",
     "shell.execute_reply.started": "2024-10-06T03:35:33.966984Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CA', 'NY', 'CA', 'FL']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandasDF= df.select(\"state\").toPandas()[\"state\"]\n",
    "res=list(pandasDF)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1c9a9adf-e8be-43a1-82ec-b96df8c62339",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T03:43:50.811272Z",
     "iopub.status.busy": "2024-10-06T03:43:50.810520Z",
     "iopub.status.idle": "2024-10-06T03:43:51.277389Z",
     "shell.execute_reply": "2024-10-06T03:43:51.276139Z",
     "shell.execute_reply.started": "2024-10-06T03:43:50.811201Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|seq|\n",
      "+---+\n",
      "|  1|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " #2 singleElement.py\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import to_timestamp,current_timestamp\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "schema = StructType([\n",
    "            StructField(\"seq\", StringType(), True)])\n",
    "data = [(\"1\",)]\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "65f93d6a-f59e-4894-946b-011195c185fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T03:54:16.681107Z",
     "iopub.status.busy": "2024-10-06T03:54:16.680329Z",
     "iopub.status.idle": "2024-10-06T03:54:16.696733Z",
     "shell.execute_reply": "2024-10-06T03:54:16.695622Z",
     "shell.execute_reply.started": "2024-10-06T03:54:16.681043Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Scott</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jeff</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thomas</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ann</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name  age\n",
       "0   Scott   50\n",
       "1    Jeff   45\n",
       "2  Thomas   54\n",
       "3     Ann   34"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #3 pandas-pyspark-dataframe.py\n",
    "\n",
    "import pandas as pd  \n",
    "data = [['Scott', 50], ['Jeff', 45], ['Thomas', 54],['Ann',34]] \n",
    "#data1 = [('Scott', 50), ('Jeff', 45), ('Thomas', 54),('Ann',34)] \n",
    "\n",
    "data\n",
    "pandasDF= pd.DataFrame(data,columns=[\"name\",\"age\"])\n",
    "pandasDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "226b377a-cf40-43f1-bcc0-8bc026fec951",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T03:54:19.041204Z",
     "iopub.status.busy": "2024-10-06T03:54:19.040729Z",
     "iopub.status.idle": "2024-10-06T03:54:19.046230Z",
     "shell.execute_reply": "2024-10-06T03:54:19.045261Z",
     "shell.execute_reply.started": "2024-10-06T03:54:19.041160Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mySchema= StructType([\n",
    "            StructField(\"first Name\",StringType(),True),\n",
    "            StructField(\"Age\",IntegerType(),True)\n",
    "        \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2cdaa436-fd30-4838-9335-b07c792717b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T03:54:21.656351Z",
     "iopub.status.busy": "2024-10-06T03:54:21.655844Z",
     "iopub.status.idle": "2024-10-06T03:54:22.043334Z",
     "shell.execute_reply": "2024-10-06T03:54:22.042281Z",
     "shell.execute_reply.started": "2024-10-06T03:54:21.656292Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- first Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      "\n",
      "+----------+---+\n",
      "|first Name|Age|\n",
      "+----------+---+\n",
      "|     Scott| 50|\n",
      "|      Jeff| 45|\n",
      "|    Thomas| 54|\n",
      "|       Ann| 34|\n",
      "+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkDF2= spark.createDataFrame(pandasDF,mySchema)\n",
    "sparkDF2.printSchema()\n",
    "sparkDF2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5f3d068a-24b1-44e5-b2da-4e1b373c3729",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T03:54:56.226094Z",
     "iopub.status.busy": "2024-10-06T03:54:56.225528Z",
     "iopub.status.idle": "2024-10-06T03:54:56.231655Z",
     "shell.execute_reply": "2024-10-06T03:54:56.230712Z",
     "shell.execute_reply.started": "2024-10-06T03:54:56.226028Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\",\"true\")\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.fallback.enabled\",\"true\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e6c08044-c387-48da-b777-682e9f83a9f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T03:57:31.222433Z",
     "iopub.status.busy": "2024-10-06T03:57:31.221206Z",
     "iopub.status.idle": "2024-10-06T03:57:33.947249Z",
     "shell.execute_reply": "2024-10-06T03:57:33.946220Z",
     "shell.execute_reply.started": "2024-10-06T03:57:31.222382Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 45, 54, 34]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandasDF2= sparkDF2.select(\"*\").toPandas()\n",
    "pandasDF2\n",
    "pandasDF2[\"first Name\"]\n",
    "list(pandasDF2[\"Age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "11793c99-7962-48c7-bb28-e35fa1146b86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T04:00:16.947771Z",
     "iopub.status.busy": "2024-10-06T04:00:16.947263Z",
     "iopub.status.idle": "2024-10-06T04:00:16.956331Z",
     "shell.execute_reply": "2024-10-06T04:00:16.955216Z",
     "shell.execute_reply.started": "2024-10-06T04:00:16.947725Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('true', 'true')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=spark.conf.get(\"spark.sql.execution.arrow.enabled\")\n",
    "test123=spark.conf.get(\"spark.sql.execution.arrow.pyspark.fallback.enabled\")\n",
    "test,test123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "fd7c85fe-2e18-484d-bfa3-e01e6b2762f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T04:32:00.176112Z",
     "iopub.status.busy": "2024-10-06T04:32:00.175624Z",
     "iopub.status.idle": "2024-10-06T04:32:01.068096Z",
     "shell.execute_reply": "2024-10-06T04:32:01.066438Z",
     "shell.execute_reply.started": "2024-10-06T04:32:00.176067Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------+\n",
      "|      date|increment|  inc_date|\n",
      "+----------+---------+----------+\n",
      "|2024-10-11|        1|2024-11-11|\n",
      "|2024-08-09|        2|2024-10-09|\n",
      "|2024-07-04|        3|2024-10-04|\n",
      "+----------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " #4 pyspark-add-month.py\n",
    "    \n",
    "data =[(\"2024-10-11\",1) ,(\"2024-08-09\",2),(\"2024-07-04\",3)]\n",
    "df= spark.createDataFrame(data,schema=[\"date\",\"increment\"]).\\\n",
    "            select(\"date\",\"increment\",\\\n",
    "                   expr(\"add_months(to_date(date,'yyyy-MM-dd'),cast(increment as Integer))\"\\\n",
    "                       ).alias(\"inc_date\")\\\n",
    "                  )\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643df5ff-21b2-40ef-a643-0a93fa72dbc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "3ba68281-bf9c-4933-b780-663bf7d19313",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T04:59:06.642906Z",
     "iopub.status.busy": "2024-10-06T04:59:06.642413Z",
     "iopub.status.idle": "2024-10-06T04:59:10.315850Z",
     "shell.execute_reply": "2024-10-06T04:59:10.314878Z",
     "shell.execute_reply.started": "2024-10-06T04:59:06.642861Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------+------+-------------+\n",
      "|firstname|lastname|gender|salary|bonus_percent|\n",
      "+---------+--------+------+------+-------------+\n",
      "|    James|   Smith|     M|  3000|          0.3|\n",
      "|     Anna|    Rose|     F|  4100|          0.3|\n",
      "|   Robert|Williams|     M|  6200|          0.3|\n",
      "+---------+--------+------+------+-------------+\n",
      "\n",
      "+---------+--------+------+------+-------------+\n",
      "|firstname|lastname|gender|salary|bonus_percent|\n",
      "+---------+--------+------+------+-------------+\n",
      "|    James|   Smith|     M|  3000|        900.0|\n",
      "|     Anna|    Rose|     F|  4100|       1230.0|\n",
      "|   Robert|Williams|     M|  6200|       1860.0|\n",
      "+---------+--------+------+------+-------------+\n",
      "\n",
      "+---------+--------+------+------+---------------+\n",
      "|firstname|lastname|gender|salary|      full_name|\n",
      "+---------+--------+------+------+---------------+\n",
      "|    James|   Smith|     M|  3000|    James,Smith|\n",
      "|     Anna|    Rose|     F|  4100|      Anna,Rose|\n",
      "|   Robert|Williams|     M|  6200|Robert,Williams|\n",
      "+---------+--------+------+------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------+------+------------+\n",
      "|firstname|lastname|gender|salary|current_date|\n",
      "+---------+--------+------+------+------------+\n",
      "|    James|   Smith|     M|  3000|  2024-10-06|\n",
      "|     Anna|    Rose|     F|  4100|  2024-10-06|\n",
      "|   Robert|Williams|     M|  6200|  2024-10-06|\n",
      "+---------+--------+------+------+------------+\n",
      "\n",
      "+---------+--------+------+------+-----+\n",
      "|firstname|lastname|gender|salary|grade|\n",
      "+---------+--------+------+------+-----+\n",
      "|    James|   Smith|     M|  3000|    A|\n",
      "|     Anna|    Rose|     F|  4100|    B|\n",
      "|   Robert|Williams|     M|  6200|    C|\n",
      "+---------+--------+------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " #4 pyspark-add-new-column.py\n",
    "    \n",
    "\n",
    "data = [('James','Smith','M',3000),\n",
    "  ('Anna','Rose','F',4100),\n",
    "  ('Robert','Williams','M',6200), \n",
    "]\n",
    "columns = [\"firstname\",\"lastname\",\"gender\",\"salary\"]\n",
    "df = spark.createDataFrame(data=data, schema = columns)\n",
    "from pyspark.sql.functions import lit\n",
    "df.withColumn(\"bonus_percent\",lit(0.3)).show()\n",
    "df.withColumn(\"bonus_percent\",df.salary *0.3).show()\n",
    "df.withColumn(\"full_name\",concat_ws(',','firstname','lastname')).show()\n",
    "df.withColumn(\"current_date\",current_date()).show()\n",
    "df.withColumn(\"grade\",\\\n",
    "              when( \n",
    "                    df.salary < 4000,lit('A')\\\n",
    "                  ).when(\\\n",
    "                  (df.salary >= 4000) & (df.salary <= 5000),lit('B')\n",
    "                        )\\\n",
    "                  .otherwise(lit('C'))).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "e488f52e-15eb-48b6-ba3b-989cbaa854f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T05:08:25.079585Z",
     "iopub.status.busy": "2024-10-06T05:08:25.079087Z",
     "iopub.status.idle": "2024-10-06T05:08:26.444945Z",
     "shell.execute_reply": "2024-10-06T05:08:26.443827Z",
     "shell.execute_reply.started": "2024-10-06T05:08:25.079538Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------------+\n",
      "|firstname|salary|bonus_amount|\n",
      "+---------+------+------------+\n",
      "|    James|  3000|         0.3|\n",
      "|     Anna|  4100|         0.3|\n",
      "|   Robert|  6200|         0.3|\n",
      "+---------+------+------------+\n",
      "\n",
      "+---------+------+------------+\n",
      "|firstname|salary|bonus_amount|\n",
      "+---------+------+------------+\n",
      "|    James|  3000|      1200.0|\n",
      "|     Anna|  4100|      1640.0|\n",
      "|   Robert|  6200|      2480.0|\n",
      "+---------+------+------------+\n",
      "\n",
      "+---------+------+-----------+\n",
      "|firstname|salary|todays_date|\n",
      "+---------+------+-----------+\n",
      "|    James|  3000| 2024-10-06|\n",
      "|     Anna|  4100| 2024-10-06|\n",
      "|   Robert|  6200| 2024-10-06|\n",
      "+---------+------+-----------+\n",
      "\n",
      "+---------+------+-----+\n",
      "|firstname|salary|grade|\n",
      "+---------+------+-----+\n",
      "|    James|  3000|    C|\n",
      "|     Anna|  4100|    C|\n",
      "|   Robert|  6200|    C|\n",
      "+---------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"firstname\",\"salary\", lit(0.3).alias(\"bonus_amount\")).show()\n",
    "df.select(\"firstname\",\"salary\", (df.salary * 0.4).alias(\"bonus_amount\")).show()\n",
    "df.select(\"firstname\",\"salary\", current_date().alias(\"todays_date\")).show()\n",
    "df.createOrReplaceTempView(\"view_df\")\n",
    "spark.sql(\"select firstname,salary,\"+\n",
    "          \"case salary \" +\n",
    "                \"when salary < 4000 then 'A' \"+\n",
    "                \"when salary >=4000 and salary <=5000 then 'B' \" +\n",
    "                 \"else 'C' \" +\n",
    "          \"end as grade \" +\n",
    "          \"from view_df\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "6ce081b7-a571-4d25-9a77-6ed25566fe24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T05:28:19.605615Z",
     "iopub.status.busy": "2024-10-06T05:28:19.605129Z",
     "iopub.status.idle": "2024-10-06T05:28:20.010596Z",
     "shell.execute_reply": "2024-10-06T05:28:20.009586Z",
     "shell.execute_reply.started": "2024-10-06T05:28:19.605569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|James        |Sales     |3000  |\n",
      "|Michael      |Sales     |4600  |\n",
      "|Robert       |Sales     |4100  |\n",
      "|Maria        |Finance   |3000  |\n",
      "|James        |Sales     |3000  |\n",
      "|Scott        |Finance   |3300  |\n",
      "|Jen          |Finance   |3900  |\n",
      "|Jeff         |Marketing |3000  |\n",
      "|Kumar        |Marketing |2000  |\n",
      "|Saif         |Sales     |4100  |\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " #5 pyspark-aggregate.py\n",
    "\n",
    "simpleData = [(\"James\", \"Sales\", 3000),\n",
    "    (\"Michael\", \"Sales\", 4600),\n",
    "    (\"Robert\", \"Sales\", 4100),\n",
    "    (\"Maria\", \"Finance\", 3000),\n",
    "    (\"James\", \"Sales\", 3000),\n",
    "    (\"Scott\", \"Finance\", 3300),\n",
    "    (\"Jen\", \"Finance\", 3900),\n",
    "    (\"Jeff\", \"Marketing\", 3000),\n",
    "    (\"Kumar\", \"Marketing\", 2000),\n",
    "    (\"Saif\", \"Sales\", 4100)\n",
    "  ]\n",
    "schema = [\"employee_name\", \"department\", \"salary\"]\n",
    "df = spark.createDataFrame(data=simpleData, schema = schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "abaed683-f249-4f7a-83a7-f13d6c6e8532",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T05:34:12.114804Z",
     "iopub.status.busy": "2024-10-06T05:34:12.113891Z",
     "iopub.status.idle": "2024-10-06T05:34:14.622254Z",
     "shell.execute_reply": "2024-10-06T05:34:14.621010Z",
     "shell.execute_reply.started": "2024-10-06T05:34:12.114745Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approx count distinct: 6\n"
     ]
    }
   ],
   "source": [
    "print(f\"approx count distinct:\",str(df.select(approx_count_distinct('salary')).collect()[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "9cca664f-8660-48f1-88cb-81b51ad8ed26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T05:38:28.224716Z",
     "iopub.status.busy": "2024-10-06T05:38:28.224152Z",
     "iopub.status.idle": "2024-10-06T05:38:30.843385Z",
     "shell.execute_reply": "2024-10-06T05:38:30.842321Z",
     "shell.execute_reply.started": "2024-10-06T05:38:28.224669Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|collect_set(department)    |\n",
      "+---------------------------+\n",
      "|[Finance, Sales, Marketing]|\n",
      "+---------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Sales',\n",
       " 'Sales',\n",
       " 'Sales',\n",
       " 'Finance',\n",
       " 'Sales',\n",
       " 'Finance',\n",
       " 'Finance',\n",
       " 'Marketing',\n",
       " 'Marketing',\n",
       " 'Sales']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res= df.agg(collect_list('department'))\n",
    "df.select(collect_set(\"department\")).show(truncate=False)\n",
    "res.collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "eb0985a6-dfbe-4780-a284-f0008e1a17f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T05:42:15.490016Z",
     "iopub.status.busy": "2024-10-06T05:42:15.489457Z",
     "iopub.status.idle": "2024-10-06T05:42:17.988101Z",
     "shell.execute_reply": "2024-10-06T05:42:17.986955Z",
     "shell.execute_reply.started": "2024-10-06T05:42:15.489968Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct Count of Department &amp; Salary: 8\n"
     ]
    }
   ],
   "source": [
    "df2= df.select(countDistinct('department','salary'))\n",
    "print(\"Distinct Count of Department &amp; Salary: \"+str(df2.collect()[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "7c48f5c2-16d9-4a8a-9ac5-13b13e338cf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T06:12:26.169125Z",
     "iopub.status.busy": "2024-10-06T06:12:26.168637Z",
     "iopub.status.idle": "2024-10-06T06:12:29.343899Z",
     "shell.execute_reply": "2024-10-06T06:12:29.342679Z",
     "shell.execute_reply.started": "2024-10-06T06:12:26.169081Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|        James|     Sales|  3000|\n",
      "|      Michael|     Sales|  4600|\n",
      "|       Robert|     Sales|  4100|\n",
      "|        Maria|   Finance|  3000|\n",
      "|        James|     Sales|  3000|\n",
      "|        Scott|   Finance|  3300|\n",
      "|          Jen|   Finance|  3900|\n",
      "|         Jeff| Marketing|  3000|\n",
      "|        Kumar| Marketing|  2000|\n",
      "|         Saif|     Sales|  4100|\n",
      "+-------------+----------+------+\n",
      "\n",
      "+-------------+\n",
      "|first(salary)|\n",
      "+-------------+\n",
      "|4100         |\n",
      "+-------------+\n",
      "\n",
      "+------------+\n",
      "|last(salary)|\n",
      "+------------+\n",
      "|4100        |\n",
      "+------------+\n",
      "\n",
      "+-------------------+\n",
      "|kurtosis(salary)   |\n",
      "+-------------------+\n",
      "|-0.6467803030303028|\n",
      "+-------------------+\n",
      "\n",
      "+-----------+\n",
      "|max(salary)|\n",
      "+-----------+\n",
      "|4600       |\n",
      "+-----------+\n",
      "\n",
      "+-----------+\n",
      "|min(salary)|\n",
      "+-----------+\n",
      "|2000       |\n",
      "+-----------+\n",
      "\n",
      "+-----------+\n",
      "|avg(salary)|\n",
      "+-----------+\n",
      "|3400.0     |\n",
      "+-----------+\n",
      "\n",
      "+--------------------+\n",
      "|skewness(salary)    |\n",
      "+--------------------+\n",
      "|-0.12041791181069564|\n",
      "+--------------------+\n",
      "\n",
      "+-------------------+-------------------+------------------+\n",
      "|stddev_samp(salary)|stddev_samp(salary)|stddev_pop(salary)|\n",
      "+-------------------+-------------------+------------------+\n",
      "|765.9416862050705  |765.9416862050705  |726.636084983398  |\n",
      "+-------------------+-------------------+------------------+\n",
      "\n",
      "+-----------+\n",
      "|sum(salary)|\n",
      "+-----------+\n",
      "|34000      |\n",
      "+-----------+\n",
      "\n",
      "+--------------------+\n",
      "|sum(DISTINCT salary)|\n",
      "+--------------------+\n",
      "|20900               |\n",
      "+--------------------+\n",
      "\n",
      "+-----------------+-----------------+---------------+\n",
      "|var_samp(salary) |var_samp(salary) |var_pop(salary)|\n",
      "+-----------------+-----------------+---------------+\n",
      "|586666.6666666666|586666.6666666666|528000.0       |\n",
      "+-----------------+-----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()\n",
    "df.select(first(\"salary\")).show(truncate=False)\n",
    "df.select(last(\"salary\")).show(truncate=False)\n",
    "df.select(kurtosis(\"salary\")).show(truncate=False)\n",
    "df.select(max(\"salary\")).show(truncate=False)\n",
    "df.select(min(\"salary\")).show(truncate=False)\n",
    "df.select(mean(\"salary\")).show(truncate=False)\n",
    "df.select(skewness(\"salary\")).show(truncate=False)\n",
    "df.select(stddev(\"salary\"), stddev_samp(\"salary\"), \\\n",
    "    stddev_pop(\"salary\")).show(truncate=False)\n",
    "df.select(sum(\"salary\")).show(truncate=False)\n",
    "df.select(sumDistinct(\"salary\")).show(truncate=False)\n",
    "df.select(variance(\"salary\"),var_samp(\"salary\"),var_pop(\"salary\")) \\\n",
    "  .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "f7f2114b-bfa2-4a2d-ae0b-e4bd0bff7806",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T06:17:05.985032Z",
     "iopub.status.busy": "2024-10-06T06:17:05.984550Z",
     "iopub.status.idle": "2024-10-06T06:17:06.357820Z",
     "shell.execute_reply": "2024-10-06T06:17:06.356592Z",
     "shell.execute_reply.started": "2024-10-06T06:17:05.984988Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|  c|\n",
      "+---+\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df10 = spark.createDataFrame([[1],[2],[3]], [\"c\"])\n",
    "df10.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "9b9a6281-da2e-47a8-b042-b181a1b8dae1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T06:21:55.570115Z",
     "iopub.status.busy": "2024-10-06T06:21:55.569593Z",
     "iopub.status.idle": "2024-10-06T06:21:55.855047Z",
     "shell.execute_reply": "2024-10-06T06:21:55.854024Z",
     "shell.execute_reply.started": "2024-10-06T06:21:55.570063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|    skewness(salary)|\n",
      "+--------------------+\n",
      "|-0.12041791181069564|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(skewness(df.salary)).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "0cd6541d-6698-45fe-8e7d-9b01c99c0df8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T06:23:46.573747Z",
     "iopub.status.busy": "2024-10-06T06:23:46.573252Z",
     "iopub.status.idle": "2024-10-06T06:23:46.798452Z",
     "shell.execute_reply": "2024-10-06T06:23:46.797481Z",
     "shell.execute_reply.started": "2024-10-06T06:23:46.573703Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|   stddev_pop(id)|\n",
      "+-----------------+\n",
      "|1.707825127659933|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.range(6).select(stddev_pop(\"id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8efeefc6-27bd-4a16-b419-0de9e8f04d33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T21:20:31.722363Z",
     "iopub.status.busy": "2024-10-06T21:20:31.721851Z",
     "iopub.status.idle": "2024-10-06T21:20:34.577158Z",
     "shell.execute_reply": "2024-10-06T21:20:34.576095Z",
     "shell.execute_reply.started": "2024-10-06T21:20:31.722294Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(\n",
    "    [(680, [[691,1], [692,5]]), (685, [[691,2], [692,2]]), (684, [[691,1], [692,3]])],\n",
    "    [\"product_PK\", \"products\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "2d973227-03b4-4f5a-b583-4e876be3d6a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T06:25:59.128250Z",
     "iopub.status.busy": "2024-10-06T06:25:59.127776Z",
     "iopub.status.idle": "2024-10-06T06:25:59.502678Z",
     "shell.execute_reply": "2024-10-06T06:25:59.501560Z",
     "shell.execute_reply.started": "2024-10-06T06:25:59.128205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|product_PK|            products|\n",
      "+----------+--------------------+\n",
      "|       680|[[691, 1], [692, 5]]|\n",
      "|       685|[[691, 2], [692, 2]]|\n",
      "|       684|[[691, 1], [692, 3]]|\n",
      "+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85440b62-35fd-415f-85a3-bddb23ddd499",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T21:21:41.853355Z",
     "iopub.status.busy": "2024-10-06T21:21:41.852879Z",
     "iopub.status.idle": "2024-10-06T21:21:41.860771Z",
     "shell.execute_reply": "2024-10-06T21:21:41.859794Z",
     "shell.execute_reply.started": "2024-10-06T21:21:41.853311Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_score = udf(lambda x : x[1],IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6017b47-0d70-4e5e-a1bf-6558fe995f25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T21:21:43.330966Z",
     "iopub.status.busy": "2024-10-06T21:21:43.330502Z",
     "iopub.status.idle": "2024-10-06T21:21:55.935627Z",
     "shell.execute_reply": "2024-10-06T21:21:55.934561Z",
     "shell.execute_reply.started": "2024-10-06T21:21:43.330924Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/10/06 21:21:45 INFO src/lib.rs: Boson native library initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------+\n",
      "|product_PK|            products|exploded|\n",
      "+----------+--------------------+--------+\n",
      "|       680|[[691, 1], [692, 5]]|[691, 1]|\n",
      "|       680|[[691, 1], [692, 5]]|[692, 5]|\n",
      "|       685|[[691, 2], [692, 2]]|[691, 2]|\n",
      "|       685|[[691, 2], [692, 2]]|[692, 2]|\n",
      "|       684|[[691, 1], [692, 3]]|[691, 1]|\n",
      "|       684|[[691, 1], [692, 3]]|[692, 3]|\n",
      "+----------+--------------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+\n",
      "|             _mean|          _stddev|\n",
      "+------------------+-----------------+\n",
      "|2.3333333333333335|1.505545305418162|\n",
      "+------------------+-----------------+\n",
      "\n",
      "+----------+--------------------+--------+\n",
      "|product_PK|            products|val_list|\n",
      "+----------+--------------------+--------+\n",
      "|       680|[[691, 1], [692, 5]]|  [1, 5]|\n",
      "|       685|[[691, 2], [692, 2]]|  [2, 2]|\n",
      "|       684|[[691, 1], [692, 3]]|  [1, 3]|\n",
      "+----------+--------------------+--------+\n",
      "\n",
      "+------------------+-----------------+\n",
      "|             _mean|           stddev|\n",
      "+------------------+-----------------+\n",
      "|2.3333333333333335|1.505545305418162|\n",
      "+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#other approach 1 using udf\n",
    "df.withColumn(\"exploded\",explode(df.products)).show()\n",
    "df_stats = df.withColumn(\"exploded\",explode(df.products))\\\n",
    "                        .withColumn(\"score\",get_score(\"exploded\")).\\\n",
    "                        select(\\\n",
    "                            mean(\"score\").alias(\"_mean\"),\\\n",
    "                            stddev(\"score\").alias(\"_stddev\"))\n",
    "df_stats.show(1000)\n",
    "\n",
    "#other approach without udf using in-built array\n",
    "df.withColumn(\"val_list\",array(df.products.getItem(0).getItem(1),df.products.getItem(1).getItem(1))).show()\n",
    "df.withColumn(\"val_list\",array(df.products.getItem(0).getItem(1),df.products.getItem(1).getItem(1)))\\\n",
    "            .withColumn(\"exploded_val\",explode(\"val_list\"))\\\n",
    "            .select(mean(\"exploded_val\").alias(\"_mean\"),\\\n",
    "                   stddev(\"exploded_val\").alias(\"stddev\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "6281db09-37e0-494b-97aa-e12004d04a10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T06:48:08.103450Z",
     "iopub.status.busy": "2024-10-06T06:48:08.102963Z",
     "iopub.status.idle": "2024-10-06T06:48:08.226553Z",
     "shell.execute_reply": "2024-10-06T06:48:08.225351Z",
     "shell.execute_reply.started": "2024-10-06T06:48:08.103404Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|   stddev_pop(id)|\n",
      "+-----------------+\n",
      "|1.707825127659933|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.range(6).select(stddev_pop(\"id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbfbe053-e7f4-4d21-bfd6-62f6756e380d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T21:41:52.701601Z",
     "iopub.status.busy": "2024-10-06T21:41:52.700884Z",
     "iopub.status.idle": "2024-10-06T21:41:53.930863Z",
     "shell.execute_reply": "2024-10-06T21:41:53.929802Z",
     "shell.execute_reply.started": "2024-10-06T21:41:52.701533Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- languagesAtSchool: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- currentState: string (nullable = true)\n",
      "\n",
      "+----------------+------------------+------------+\n",
      "|name            |languagesAtSchool |currentState|\n",
      "+----------------+------------------+------------+\n",
      "|James,,Smith    |[Java, Scala, C++]|CA          |\n",
      "|Michael,Rose,   |[Spark, Java, C++]|NJ          |\n",
      "|Robert,,Williams|[CSharp, VB]      |NV          |\n",
      "+----------------+------------------+------------+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- languagesAtSchool: string (nullable = false)\n",
      " |-- currentState: string (nullable = true)\n",
      "\n",
      "+----------------+-----------------+------------+\n",
      "|name            |languagesAtSchool|currentState|\n",
      "+----------------+-----------------+------------+\n",
      "|James,,Smith    |Java,Scala,C++   |CA          |\n",
      "|Michael,Rose,   |Spark,Java,C++   |NJ          |\n",
      "|Robert,,Williams|CSharp,VB        |NV          |\n",
      "+----------------+-----------------+------------+\n",
      "\n",
      "+-----------------+\n",
      "|languagesAtSchool|\n",
      "+-----------------+\n",
      "|   Java,Scala,C++|\n",
      "|   Spark,Java,C++|\n",
      "|        CSharp,VB|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " #5 pyspark-array-string.py\n",
    "columns = [\"name\",\"languagesAtSchool\",\"currentState\"]\n",
    "data = [(\"James,,Smith\",[\"Java\",\"Scala\",\"C++\"],\"CA\"), \\\n",
    "    (\"Michael,Rose,\",[\"Spark\",\"Java\",\"C++\"],\"NJ\"), \\\n",
    "    (\"Robert,,Williams\",[\"CSharp\",\"VB\"],\"NV\")]\n",
    "\n",
    "df = spark.createDataFrame(data=data,schema=columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "\n",
    "df2= df.withColumn(\"languagesAtSchool\",concat_ws(\",\",\"languagesAtSchool\"))\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)\n",
    "df.createOrReplaceTempView(\"ARRAY_STRING\")\n",
    "spark.sql(\"select concat_ws(',',languagesAtSchool) as languagesAtSchool  from ARRAY_STRING\").show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0b37d6d-4389-4856-9cf1-04ba546db609",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T21:48:30.653072Z",
     "iopub.status.busy": "2024-10-06T21:48:30.652592Z",
     "iopub.status.idle": "2024-10-06T21:48:31.750839Z",
     "shell.execute_reply": "2024-10-06T21:48:31.749851Z",
     "shell.execute_reply.started": "2024-10-06T21:48:30.653030Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- languagesAtSchool: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- languagesAtWork: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- currentState: string (nullable = true)\n",
      " |-- previousState: string (nullable = true)\n",
      "\n",
      "+----------------+------------------+---------------+------------+-------------+\n",
      "|            name| languagesAtSchool|languagesAtWork|currentState|previousState|\n",
      "+----------------+------------------+---------------+------------+-------------+\n",
      "|    James,,Smith|[Java, Scala, C++]|  [Spark, Java]|          OH|           CA|\n",
      "|   Michael,Rose,|[Spark, Java, C++]|  [Spark, Java]|          NY|           NJ|\n",
      "|Robert,,Williams|      [CSharp, VB]|[Spark, Python]|          UT|           NV|\n",
      "+----------------+------------------+---------------+------------+-------------+\n",
      "\n",
      "+----------------+------+\n",
      "|            name|   col|\n",
      "+----------------+------+\n",
      "|    James,,Smith|  Java|\n",
      "|    James,,Smith| Scala|\n",
      "|    James,,Smith|   C++|\n",
      "|   Michael,Rose,| Spark|\n",
      "|   Michael,Rose,|  Java|\n",
      "|   Michael,Rose,|   C++|\n",
      "|Robert,,Williams|CSharp|\n",
      "|Robert,,Williams|    VB|\n",
      "+----------------+------+\n",
      "\n",
      "+--------------------+\n",
      "|         nameAsArray|\n",
      "+--------------------+\n",
      "|    [James, , Smith]|\n",
      "|   [Michael, Rose, ]|\n",
      "|[Robert, , Williams]|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " #6 pyspark-arraytype.py\n",
    "data = [\n",
    " (\"James,,Smith\",[\"Java\",\"Scala\",\"C++\"],[\"Spark\",\"Java\"],\"OH\",\"CA\"),\n",
    " (\"Michael,Rose,\",[\"Spark\",\"Java\",\"C++\"],[\"Spark\",\"Java\"],\"NY\",\"NJ\"),\n",
    " (\"Robert,,Williams\",[\"CSharp\",\"VB\"],[\"Spark\",\"Python\"],\"UT\",\"NV\")\n",
    "]\n",
    "schema = StructType([ \n",
    "    StructField(\"name\",StringType(),True), \n",
    "    StructField(\"languagesAtSchool\",ArrayType(StringType()),True), \n",
    "    StructField(\"languagesAtWork\",ArrayType(StringType()),True), \n",
    "    StructField(\"currentState\", StringType(), True), \n",
    "    StructField(\"previousState\", StringType(), True) \n",
    "  ])\n",
    "df = spark.createDataFrame(data=data,schema=schema)\n",
    "df.printSchema()\n",
    "df.show()\n",
    "#explode\n",
    "df.select(\"name\", explode(\"languagesAtSchool\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1fb75e19-8199-4c82-8cef-b4562f4cc542",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T21:55:09.953152Z",
     "iopub.status.busy": "2024-10-06T21:55:09.952646Z",
     "iopub.status.idle": "2024-10-06T21:55:11.368443Z",
     "shell.execute_reply": "2024-10-06T21:55:11.367432Z",
     "shell.execute_reply.started": "2024-10-06T21:55:09.953109Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|         nameAsArray|\n",
      "+--------------------+\n",
      "|    [James, , Smith]|\n",
      "|   [Michael, Rose, ]|\n",
      "|[Robert, , Williams]|\n",
      "+--------------------+\n",
      "\n",
      "+-----------+\n",
      "|nameAsArray|\n",
      "+-----------+\n",
      "|      James|\n",
      "|           |\n",
      "|      Smith|\n",
      "|    Michael|\n",
      "|       Rose|\n",
      "|           |\n",
      "|     Robert|\n",
      "|           |\n",
      "|   Williams|\n",
      "+-----------+\n",
      "\n",
      "+----------------------------------+\n",
      "|array(currentState, previousState)|\n",
      "+----------------------------------+\n",
      "|                          [OH, CA]|\n",
      "|                          [NY, NJ]|\n",
      "|                          [UT, NV]|\n",
      "+----------------------------------+\n",
      "\n",
      "+----------------+--------------+\n",
      "|            name|array_contains|\n",
      "+----------------+--------------+\n",
      "|    James,,Smith|          true|\n",
      "|   Michael,Rose,|          true|\n",
      "|Robert,,Williams|          true|\n",
      "+----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#split\n",
    "df.select(split(df.name,\",\").alias(\"nameAsArray\")).show()\n",
    "df2=df.select(explode(split(df.name,\",\")).alias(\"nameAsArray\"))\n",
    "df2.show()\n",
    "#array\n",
    "df.select(array(\"currentState\",\"previousState\")).show()\n",
    "#array_contains\n",
    "df.select(df.name,array_contains(df.languagesAtWork,\"Spark\").alias(\"array_contains\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0c10ee10-7476-4adb-94c4-040d8f835d46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T22:12:04.295383Z",
     "iopub.status.busy": "2024-10-06T22:12:04.294425Z",
     "iopub.status.idle": "2024-10-06T22:12:05.651438Z",
     "shell.execute_reply": "2024-10-06T22:12:05.650114Z",
     "shell.execute_reply.started": "2024-10-06T22:12:04.295338Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n",
      "+---------+--------+-------+-----+\n",
      "|firstname|lastname|country|state|\n",
      "+---------+--------+-------+-----+\n",
      "|James    |Smith   |USA    |CA   |\n",
      "|Michael  |Rose    |USA    |NY   |\n",
      "|Robert   |Williams|USA    |CA   |\n",
      "|Maria    |Jones   |USA    |FL   |\n",
      "|Dan      |Anshuman|CANADA |BC   |\n",
      "+---------+--------+-------+-----+\n",
      "\n",
      "+---------+--------+-------+----------+\n",
      "|firstname|lastname|country|     state|\n",
      "+---------+--------+-------+----------+\n",
      "|    James|   Smith|    USA|California|\n",
      "|  Michael|    Rose|    USA|  New York|\n",
      "|   Robert|Williams|    USA|California|\n",
      "|    Maria|   Jones|    USA|   Florida|\n",
      "|      Dan|Anshuman| CANADA|      null|\n",
      "+---------+--------+-------+----------+\n",
      "\n",
      "+---------+--------+-------+-----+\n",
      "|firstname|lastname|country|state|\n",
      "+---------+--------+-------+-----+\n",
      "|    James|   Smith|    USA|   CA|\n",
      "|  Michael|    Rose|    USA|   NY|\n",
      "|   Robert|Williams|    USA|   CA|\n",
      "|    Maria|   Jones|    USA|   FL|\n",
      "+---------+--------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " #7 pyspark-broadcast-dataframe.py\n",
    "states = {\"NY\":\"New York\", \"CA\":\"California\", \"FL\":\"Florida\"}\n",
    "broadcastStates = spark.sparkContext.broadcast(states)\n",
    "\n",
    "data = [(\"James\",\"Smith\",\"USA\",\"CA\"),\n",
    "    (\"Michael\",\"Rose\",\"USA\",\"NY\"),\n",
    "    (\"Robert\",\"Williams\",\"USA\",\"CA\"),\n",
    "    (\"Maria\",\"Jones\",\"USA\",\"FL\"),\n",
    "        (\"Dan\",\"Anshuman\",\"CANADA\",\"BC\")\n",
    "  ]\n",
    "\n",
    "columns = [\"firstname\",\"lastname\",\"country\",\"state\"]\n",
    "df = spark.createDataFrame(data = data, schema = columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "\n",
    "\n",
    "def state_convert(code):\n",
    "    #handle exception for keys not present in dictionary\n",
    "    if code in states.keys():\n",
    "        return broadcastStates.value[code]\n",
    "    \n",
    "\n",
    "#create df with full state name\n",
    "dfEnrich = df.rdd.map(lambda x: (x[0],x[1],x[2],state_convert(x[3]))).toDF(columns)\n",
    "dfEnrich.show()\n",
    "\n",
    "#res=([x[0] for x in broadcastStates.value.items()])\n",
    "#print(res)\n",
    "\n",
    "#filter broadcast variable\n",
    "filteDf= df.where((df['state'].isin(([x[0] for x in broadcastStates.value.items()]))))\n",
    "filteDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e85b1cba-aa18-4e13-89bb-ea22a21992a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T22:42:55.075597Z",
     "iopub.status.busy": "2024-10-06T22:42:55.074943Z",
     "iopub.status.idle": "2024-10-06T22:42:57.025890Z",
     "shell.execute_reply": "2024-10-06T22:42:57.024902Z",
     "shell.execute_reply.started": "2024-10-06T22:42:55.075538Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- jobStartDate: string (nullable = true)\n",
      " |-- isGraduated: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: double (nullable = true)\n",
      "\n",
      "+---------+---+------------+-----------+------+------+\n",
      "|firstname|age|jobStartDate|isGraduated|gender|salary|\n",
      "+---------+---+------------+-----------+------+------+\n",
      "|James    |34 |2006-01-01  |true       |M     |3000.6|\n",
      "|Michael  |33 |1980-01-10  |true       |F     |3300.8|\n",
      "|Robert   |37 |06-01-1992  |false      |M     |5000.5|\n",
      "+---------+---+------------+-----------+------+------+\n",
      "\n",
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- jobStartDate: date (nullable = true)\n",
      " |-- isGraduated: boolean (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- jobStartDate: string (nullable = true)\n",
      " |-- isGraduated: boolean (nullable = true)\n",
      "\n",
      "root\n",
      " |-- age: string (nullable = true)\n",
      " |-- isGraduated: boolean (nullable = true)\n",
      " |-- jobStartDate: date (nullable = true)\n",
      "\n",
      "+---+-----------+------------+\n",
      "|age|isGraduated|jobStartDate|\n",
      "+---+-----------+------------+\n",
      "|34 |true       |2006-01-01  |\n",
      "|33 |true       |1980-01-10  |\n",
      "|37 |false      |null        |\n",
      "+---+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " #8 pyspark-cast-column.py\n",
    "simpleData = [(\"James\",34,\"2006-01-01\",\"true\",\"M\",3000.60),\n",
    "    (\"Michael\",33,\"1980-01-10\",\"true\",\"F\",3300.80),\n",
    "    (\"Robert\",37,\"06-01-1992\",\"false\",\"M\",5000.50)\n",
    "  ]\n",
    "\n",
    "columns = [\"firstname\",\"age\",\"jobStartDate\",\"isGraduated\",\"gender\",\"salary\"]\n",
    "df = spark.createDataFrame(data = simpleData, schema = columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "\n",
    "df2=df.withColumn(\"age\",col(\"age\").cast(IntegerType()))\\\n",
    "            .withColumn(\"isGraduated\",col(\"isGraduated\").cast(BooleanType()))\\\n",
    "            .withColumn(\"jobStartDate\",col(\"jobStartDate\").cast(DateType()))\n",
    "df2.printSchema()\n",
    "\n",
    "df3= df.selectExpr(\"cast(age as int) as age\",\n",
    "                  \"cast(jobStartDate as string) as jobStartDate\",\n",
    "                   \"cast(isGraduated as Boolean) as isGraduated\",\n",
    "                  )\n",
    "df3.printSchema()\n",
    "df3.createOrReplaceTempView(\"CastExample\")\n",
    "df4 = spark.sql(\"SELECT STRING(age),BOOLEAN(isGraduated),DATE(jobStartDate) from CastExample\")\n",
    "df4.printSchema()\n",
    "df4.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "08cd5f46-bda2-409d-b79e-a47da83a9952",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T22:50:17.988116Z",
     "iopub.status.busy": "2024-10-06T22:50:17.987606Z",
     "iopub.status.idle": "2024-10-06T22:50:18.567732Z",
     "shell.execute_reply": "2024-10-06T22:50:18.566734Z",
     "shell.execute_reply.started": "2024-10-06T22:50:17.988072Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- isGraduated: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      "\n",
      "+---------+---+-----------+------+---------+\n",
      "|firstname|age|isGraduated|gender|salary   |\n",
      "+---------+---+-----------+------+---------+\n",
      "|James    |34 |true       |M     |3000.6089|\n",
      "|Michael  |33 |true       |F     |3300.8067|\n",
      "|Robert   |37 |false      |M     |5000.5034|\n",
      "+---------+---+-----------+------+---------+\n",
      "\n",
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- isGraduated: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- isGraduated: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- salary: double (nullable = true)\n",
      "\n",
      "James,34\n",
      "Michael,33\n",
      "Robert,37\n"
     ]
    }
   ],
   "source": [
    " #8 pyspark-change-string-double.py\n",
    "    \n",
    "simpleData = [(\"James\",\"34\",\"true\",\"M\",\"3000.6089\"),\n",
    "    (\"Michael\",\"33\",\"true\",\"F\",\"3300.8067\"),\n",
    "    (\"Robert\",\"37\",\"false\",\"M\",\"5000.5034\")\n",
    "  ]\n",
    "columns = [\"firstname\",\"age\",\"isGraduated\",\"gender\",\"salary\"]\n",
    "df = spark.createDataFrame(data = simpleData, schema = columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "\n",
    "df.withColumn(\"salary\",df.salary.cast(DoubleType())).printSchema()\n",
    "df.withColumn(\"salary\",df.salary.cast(\"double\")).printSchema()\n",
    "df.selectExpr(\"cast(salary as double) as salary\").printSchema()\n",
    "res=df.collect()\n",
    "for row in res:\n",
    "    print(row[\"firstname\"] +\",\"+str(row[\"age\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ed5483ae-9ae4-4395-9aff-5319a7d3a797",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T04:51:45.604345Z",
     "iopub.status.busy": "2024-10-07T04:51:45.603850Z",
     "iopub.status.idle": "2024-10-07T04:51:46.439972Z",
     "shell.execute_reply": "2024-10-07T04:51:46.438900Z",
     "shell.execute_reply.started": "2024-10-07T04:51:45.604291Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|     input|\n",
      "+----------+\n",
      "|02-03-2013|\n",
      "|05-06-2023|\n",
      "+----------+\n",
      "\n",
      "root\n",
      " |-- input: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- input: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      "\n",
      "+----------+----------+\n",
      "|     input|      date|\n",
      "+----------+----------+\n",
      "|02-03-2013|2013-03-02|\n",
      "|05-06-2023|2023-06-05|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " #9 pyspark-string-date.py\n",
    "\n",
    "df=spark.createDataFrame([[\"02-03-2013\"],[\"05-06-2023\"]],[\"input\"])\n",
    "df.show()\n",
    "df.printSchema()\n",
    "df=df.select(\"input\",to_date(\"input\",\"dd-MM-yyyy\").alias(\"date\"))\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "41293769-bd10-4030-b164-c2b09e2e7801",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T05:12:37.402151Z",
     "iopub.status.busy": "2024-10-07T05:12:37.401646Z",
     "iopub.status.idle": "2024-10-07T05:12:38.561568Z",
     "shell.execute_reply": "2024-10-07T05:12:38.560496Z",
     "shell.execute_reply.started": "2024-10-07T05:12:37.402106Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- input_timestamp: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- input_timestamp: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n",
      "+---+-----------------------+-----------------------+\n",
      "|id |input_timestamp        |timestamp              |\n",
      "+---+-----------------------+-----------------------+\n",
      "|1  |2019-06-24 12:01:19.333|2019-06-24 12:01:19.333|\n",
      "+---+-----------------------+-----------------------+\n",
      "\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- input_timestamp: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestamp_as_date: date (nullable = true)\n",
      " |-- timestamp_as_string: string (nullable = true)\n",
      "\n",
      "+---+-----------------------+-----------------------+-----------------+-----------------------+\n",
      "|id |input_timestamp        |timestamp              |timestamp_as_date|timestamp_as_string    |\n",
      "+---+-----------------------+-----------------------+-----------------+-----------------------+\n",
      "|1  |2019-06-24 12:01:19.333|2019-06-24 12:01:19.333|2019-06-24       |2019-06-24 12:01:19.333|\n",
      "+---+-----------------------+-----------------------+-----------------+-----------------------+\n",
      "\n",
      "+-------------------+\n",
      "|      timestamp_new|\n",
      "+-------------------+\n",
      "|2024-11-09 12:01:19|\n",
      "+-------------------+\n",
      "\n",
      "+-----------------------+\n",
      "|timestamp_new1         |\n",
      "+-----------------------+\n",
      "|2019-06-24 12:01:19.333|\n",
      "+-----------------------+\n",
      "\n",
      "+-----------------------+\n",
      "|timestamp_new2         |\n",
      "+-----------------------+\n",
      "|2019-06-24 12:01:19.333|\n",
      "+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " #10 pyspark-string-timestamp.py\n",
    "df=spark.createDataFrame(\n",
    "        data = [ (\"1\",\"2019-06-24 12:01:19.333\")],\n",
    "        schema=[\"id\",\"input_timestamp\"])\n",
    "df.printSchema()\n",
    "df= df.withColumn(\"timestamp\",to_timestamp(\"input_timestamp\"))\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "df= df.withColumn(\"timestamp_as_date\",to_timestamp(\"input_timestamp\").cast(DateType()))\n",
    "df= df.withColumn(\"timestamp_as_string\",to_timestamp(\"input_timestamp\").cast(StringType()))\n",
    "df= df.withColumn(\"timestamp_as_string\",to_timestamp(\"input_timestamp\").cast(\"string\"))\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "df.select(to_timestamp(lit('2024-11-09 12:01:19.000'),'yyyy-MM-dd HH:mm:ss.SSSS').alias(\"timestamp_new\")).show()\n",
    "spark.sql(\"select to_timestamp('2019-06-24 12:01:19.333','yyyy-MM-dd HH:mm:ss.SSSS') as timestamp_new1\").show(truncate=False)\n",
    "spark.sql(\"select to_timestamp('2019-06-24 12:01:19.333') as timestamp_new2\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ed6a068b-7ccd-4a52-9b9f-a29e3ca50ae5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T05:39:10.304051Z",
     "iopub.status.busy": "2024-10-07T05:39:10.303547Z",
     "iopub.status.idle": "2024-10-07T05:39:10.643343Z",
     "shell.execute_reply": "2024-10-07T05:39:10.641830Z",
     "shell.execute_reply.started": "2024-10-07T05:39:10.304006Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- dob_year: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+--------------------+--------+------+------+\n",
      "|name                |dob_year|gender|salary|\n",
      "+--------------------+--------+------+------+\n",
      "|James, A, Smith     |2018    |M     |3000  |\n",
      "|Michael, Rose, Jones|2010    |M     |4000  |\n",
      "|Robert,K,Williams   |2010    |M     |4000  |\n",
      "|Maria,Anne,Jones    |2005    |F     |4000  |\n",
      "|Jen,Mary,Brown      |2010    |      |-1    |\n",
      "+--------------------+--------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#11 pyspark-string-to-array.py\n",
    "data = [(\"James, A, Smith\",\"2018\",\"M\",3000),\n",
    "            (\"Michael, Rose, Jones\",\"2010\",\"M\",4000),\n",
    "            (\"Robert,K,Williams\",\"2010\",\"M\",4000),\n",
    "            (\"Maria,Anne,Jones\",\"2005\",\"F\",4000),\n",
    "            (\"Jen,Mary,Brown\",\"2010\",\"\",-1)\n",
    "            ]\n",
    "\n",
    "columns=[\"name\",\"dob_year\",\"gender\",\"salary\"]\n",
    "df=spark.createDataFrame(data,columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "8ffac298-c593-4a4b-8546-d75761748b33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T05:53:32.145801Z",
     "iopub.status.busy": "2024-10-07T05:53:32.145320Z",
     "iopub.status.idle": "2024-10-07T05:53:32.813211Z",
     "shell.execute_reply": "2024-10-07T05:53:32.812184Z",
     "shell.execute_reply.started": "2024-10-07T05:53:32.145759Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- dept: string (nullable = true)\n",
      " |-- properties: struct (nullable = true)\n",
      " |    |-- salary: integer (nullable = true)\n",
      " |    |-- location: string (nullable = true)\n",
      "\n",
      "+-----+---------+-----------+\n",
      "|   id|     dept| properties|\n",
      "+-----+---------+-----------+\n",
      "|36636|  Finance|{3000, USA}|\n",
      "|40288|  Finance|{5000, IND}|\n",
      "|42114|    Sales|{3900, USA}|\n",
      "|39192|Marketing|{2500, CAN}|\n",
      "|34534|    Sales|{6500, USA}|\n",
      "+-----+---------+-----------+\n",
      "\n",
      "+-----+---------+-----------+--------------------+\n",
      "|   id|     dept| properties|       propertiesMap|\n",
      "+-----+---------+-----------+--------------------+\n",
      "|36636|  Finance|{3000, USA}|{salary -> 3000, ...|\n",
      "|40288|  Finance|{5000, IND}|{salary -> 5000, ...|\n",
      "|42114|    Sales|{3900, USA}|{salary -> 3900, ...|\n",
      "|39192|Marketing|{2500, CAN}|{salary -> 2500, ...|\n",
      "|34534|    Sales|{6500, USA}|{salary -> 6500, ...|\n",
      "+-----+---------+-----------+--------------------+\n",
      "\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- dept: string (nullable = true)\n",
      " |-- properties: struct (nullable = true)\n",
      " |    |-- salary: integer (nullable = true)\n",
      " |    |-- location: string (nullable = true)\n",
      " |-- propertiesMap: map (nullable = false)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#12 pyspark-struct-to-map.py\n",
    "\n",
    "data = [ (\"36636\",\"Finance\",(3000,\"USA\")), \n",
    "    (\"40288\",\"Finance\",(5000,\"IND\")), \n",
    "    (\"42114\",\"Sales\",(3900,\"USA\")), \n",
    "    (\"39192\",\"Marketing\",(2500,\"CAN\")), \n",
    "    (\"34534\",\"Sales\",(6500,\"USA\")) ]\n",
    "\n",
    "schema = StructType([\n",
    "            StructField('id',StringType(),True),\n",
    "            StructField('dept',StringType(),True),\n",
    "            StructField('properties', StructType([\n",
    "                            StructField('salary',IntegerType(),True),\n",
    "                            StructField('location',StringType(),True)\n",
    "                            ]))  \n",
    "])\n",
    "df= spark.createDataFrame(data=data,schema=schema)\n",
    "df.printSchema()\n",
    "df.show()\n",
    "#Convert struct type to Map\n",
    "df= df.withColumn(\"propertiesMap\",create_map(\n",
    "                    lit(\"salary\"),col(\"properties.salary\"),\n",
    "                    lit(\"country\"),col(\"properties.location\")\n",
    "                    ))\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "97c11e57-2166-49ef-afac-bdabe35bd743",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T06:02:38.288156Z",
     "iopub.status.busy": "2024-10-07T06:02:38.287678Z",
     "iopub.status.idle": "2024-10-07T06:02:38.959142Z",
     "shell.execute_reply": "2024-10-07T06:02:38.957772Z",
     "shell.execute_reply.started": "2024-10-07T06:02:38.288114Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- dept: string (nullable = true)\n",
      " |-- properties: struct (nullable = true)\n",
      " |    |-- salary: integer (nullable = true)\n",
      " |    |-- country: string (nullable = true)\n",
      "\n",
      "+------+-------+\n",
      "|salary|country|\n",
      "+------+-------+\n",
      "|  3000|    USA|\n",
      "|  5000|    IND|\n",
      "|  3900|    USA|\n",
      "|  2500|    CAN|\n",
      "|  6500|    USA|\n",
      "+------+-------+\n",
      "\n",
      "+-----+---------+-----------+--------------------------------+\n",
      "|id   |dept     |properties |propertiesMap                   |\n",
      "+-----+---------+-----------+--------------------------------+\n",
      "|36636|Finance  |{3000, USA}|{salary -> 3000, country -> USA}|\n",
      "|40288|Finance  |{5000, IND}|{salary -> 5000, country -> IND}|\n",
      "|42114|Sales    |{3900, USA}|{salary -> 3900, country -> USA}|\n",
      "|39192|Marketing|{2500, CAN}|{salary -> 2500, country -> CAN}|\n",
      "|34534|Sales    |{6500, USA}|{salary -> 6500, country -> USA}|\n",
      "+-----+---------+-----------+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = [ (\"36636\",\"Finance\",(3000,\"USA\")), \n",
    "    (\"40288\",\"Finance\",(5000,\"IND\")), \n",
    "    (\"42114\",\"Sales\",(3900,\"USA\")), \n",
    "    (\"39192\",\"Marketing\",(2500,\"CAN\")), \n",
    "    (\"34534\",\"Sales\",(6500,\"USA\")) ]\n",
    "\n",
    "schema = StructType([\n",
    "        StructField(\"id\",StringType(),True),\n",
    "        StructField(\"dept\",StringType(),True),\n",
    "        StructField(\"properties\", StructType([\n",
    "                StructField(\"salary\",IntegerType(),True),\n",
    "                StructField(\"country\",StringType(),True)\n",
    "                ]))\n",
    "])\n",
    "\n",
    "df= spark.createDataFrame(data=data,schema=schema)\n",
    "df.printSchema()\n",
    "df.select(col('properties.salary'),col('properties.country')).show()\n",
    "df=df.withColumn(\"propertiesMap\", create_map(\n",
    "                    lit(\"salary\"),col('properties.salary'),\n",
    "                    lit(\"country\"),col('properties.country'),\n",
    "                    ))\n",
    "df.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 3.4.0",
   "language": "python",
   "name": "spark-3.4.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
